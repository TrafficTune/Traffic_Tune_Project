{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a145c81c2dbf7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Traffic Tune - Optimizing Traffic Signals with Reinforcement Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the Traffic Tune POC notebook. Our project focused on optimizing traffic signal control using reinforcement learning. Traffic congestion is a major problem in urban areas, leading to increased travel times, fuel consumption, and pollution. Traditional traffic signal control systems often struggle to adapt to dynamic traffic conditions, resulting in suboptimal traffic flow.\n",
    "\n",
    "Traffic Tune is a recommendation system that leverages reinforcement learning to dynamically adjust traffic signals at intersections. By learning from traffic patterns in real-time, Traffic Tune aims to improve traffic flow, reduce congestion, and enhance overall transportation efficiency.\n",
    "\n",
    "In this POC, we will demonstrate how to train a reinforcement learning agent to optimize traffic signal control in a simulated environment. We will use the SUMO (Simulation of Urban MObility) traffic simulation tool and the Stable Baselines3 library to train a Deep Q-Network (DQN) agent to learn an optimal traffic signal control policy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476f7866dc519ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup and Installations"
   ]
  },
  {
   "cell_type": "code",
   "id": "1dd2f124c075086e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "import traci\n",
    "import sumo_rl\n",
    "import os\n",
    "import sys\n",
    "from sumo_rl import SumoEnvironment\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "import imageio.v2 as imageio\n",
    "from IPython.display import Video\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "print(\"SUMO_HOME:\", os.environ.get(\"SUMO_HOME\"))\n",
    "# Get the path to the installed sumo-rl package\n",
    "sumo_rl_path = os.path.dirname(sumo_rl.__file__)\n",
    "print(\"Path to sumo-rl package:\", sumo_rl_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##########################################################################################################################",
   "id": "fc2400665a5949c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import traci\n",
    "import sumo_rl\n",
    "import os\n",
    "import sys\n",
    "from sumo_rl import SumoEnvironment\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import DQN\n",
    "import imageio.v2 as imageio\n",
    "from IPython.display import Video\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n"
   ],
   "id": "870d3614565b897e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ray import rllib\n",
    "from ray import tune\n",
    "import numpy\n",
    "import env_manager as env_manager\n",
    "import ppo_trainer as ppo_trainer"
   ],
   "id": "325ce834970de795",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "env setup",
   "id": "9ca6bdb038bc5642"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "manager = env_manager.EnvManager(\"SingleAgentEnvironment\", \"/Users/md/Desktop/Traffic_Tune_Project/env_config.json\")\n",
    "generator = manager.env_generator(\"/Users/md/Desktop/Traffic_Tune_Project/example_single_intersection\")\n",
    "rou , csv = next(generator)\n",
    "print(rou)\n",
    "print(csv)\n",
    "env_kwargs = manager.initialize_env1(rou, csv)\n",
    "print(env_kwargs)"
   ],
   "id": "3dbaca67cce7f5c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "agent setup",
   "id": "b64cd532db18accd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppo_agent = ppo_trainer.PPOTrainer(\"ppo_config.json\", manager)\n",
    "\n",
    "ppo_agent.build_config(env_kwargs)"
   ],
   "id": "8309087ffdba4187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "agent training",
   "id": "ffd34e669e6861c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = ppo_agent.train()",
   "id": "94b0bb667ed4bf91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "agent prediction",
   "id": "51f4ac4280880d68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ppo_agent.evaluate(results=results, kwargs=env_kwargs)",
   "id": "c49972e77b501485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best = results.get_best_result(\"env_runners/episode_reward_mean\", \"max\")\n",
    "print(best)\n"
   ],
   "id": "106ea8376d47f062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "############################################################################################################",
   "id": "508855efaaf6cc46"
  },
  {
   "cell_type": "markdown",
   "id": "5122a44c934ecace",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "20a1c5c1ea8804ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fe877000aead3f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup Timestamp for Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1bae4701ff6a6ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "jerusalem_tz = pytz.timezone('Asia/Jerusalem')\n",
    "\n",
    "jerusalem_time = datetime.now(jerusalem_tz)\n",
    "\n",
    "# Format the timestamp\n",
    "timestamp = jerusalem_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"Timestamp: {timestamp}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "638c394ecfe91965",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SUMO Package Path and Configuration File\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a7740527d1c3b92a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "package_path = os.path.dirname(sumo_rl.__file__)\n",
    "sumo_cfg_path = os.path.join(package_path, \"nets/single-intersection/single-intersection.sumocfg\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc9aa04632b33891",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Environment preparations"
   ]
  },
  {
   "cell_type": "code",
   "id": "e431006c47b6a062",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "def initialize_sumo_environment(num_seconds, min_green, max_green,title ):\n",
    "    env = SumoEnvironment(\n",
    "        net_file=f\"{package_path}/nets/single-intersection/single-intersection.net.xml\",\n",
    "        route_file=f\"{package_path}/nets/single-intersection/single-intersection.rou.xml\",\n",
    "        out_csv_name=f\"Outputs/single-intersection/{title}/dqn_{timestamp}\",\n",
    "        single_agent=True,\n",
    "        use_gui=False,\n",
    "        num_seconds=num_seconds,\n",
    "        min_green=min_green,\n",
    "        max_green=max_green,\n",
    "    )\n",
    "    return env\n",
    "\n",
    "\n",
    "num_seconds = 3600\n",
    "min_green = 5\n",
    "max_green = 50\n",
    "\n",
    "\n",
    "env_dqn_agent = initialize_sumo_environment(num_seconds, min_green, max_green, 'DQN_Agent_Training')\n",
    "print(\"Environment initialized for DQN Agent\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "132335f67211fa04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "id": "7be48f05cb446696",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def initialize_models(env_dqn_agent):\n",
    "    policy_kwargs = dict(\n",
    "        net_arch=[128, 128]  # Two hidden layers with 128 units each\n",
    "    ) # Optional: Change the architecture of the policy network\n",
    "    \n",
    "    rl_model_params = {\n",
    "        \"env\": env_dqn_agent,\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"learning_starts\": 100,\n",
    "        \"gamma\": 0.95,\n",
    "        \"train_freq\": 10,\n",
    "        \"target_update_interval\": 1,\n",
    "        \"exploration_initial_eps\": 0.5,\n",
    "        \"exploration_final_eps\": 0.01,\n",
    "        \"verbose\": 2,\n",
    "    }\n",
    "\n",
    "    rl_model = DQN(**rl_model_params)\n",
    "\n",
    "    return rl_model\n",
    "\n",
    "rl_model = initialize_models(env_dqn_agent)\n",
    "print(\"Models initialized\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Observation space:\", env_dqn_agent.observation_space) #Input size\n",
    "print(\"Shape of observation space:\", env_dqn_agent.observation_space.shape)\n",
    "print(\"Action space:\", env_dqn_agent.action_space) # Output size\n",
    "print(\"Number of actions:\", env_dqn_agent.action_space.n)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84ac33eeb1af939b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74d3c8757ed86b19",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0798a29d5c2e92d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Run the following code to get the path to the SUMO remote server\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9cfb0e118feaf85a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use the package path in your command\n",
    "if package_path:\n",
    "    cmd = f\"sumo-gui -c {sumo_cfg_path} --remote-port 65533\"\n",
    "    print(\"Run the following command in the terminal to start the SUMO server:\")\n",
    "    print(cmd)\n",
    "else:\n",
    "    print(\"sumo-rl package not found. Make sure it is installed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7e7c92cffe4fc92",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Connecting to SUMO server...\")\n",
    "    traci.connect(port=65533)\n",
    "    print(\"Connected to SUMO server\")\n",
    "    \n",
    "    \n",
    "    num_of_episodes = 10\n",
    "    print(\"Starting training\")\n",
    "    rl_model.learn(total_timesteps=(720*num_of_episodes))\n",
    "    print(\"Training completed\")\n",
    "\n",
    "    # Save the model\n",
    "    rl_model.save(f'savedAgent/single-intersection/dqnEpNum{num_of_episodes}_{timestamp}')\n",
    "    print(\"Model saved\")\n",
    "\n",
    "    # Close the TraCI connection\n",
    "    traci.close()\n",
    "    print(\"TraCI connection closed\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59a533d7c9299e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Agent Prediction"
   ]
  },
  {
   "cell_type": "code",
   "id": "d26cff822e3363fb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def save_figures(output_path, title):\n",
    "    file_name = f\"{title}\"\n",
    "    file_path = os.path.join(output_path, file_name)\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"Figure saved as: {file_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "53ca2db5558d0998",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def capture_screenshot(output_path, episode, step):\n",
    "    file_name = f\"episode_{episode}_step_{step}.png\"\n",
    "    file_path = os.path.join(output_path, file_name)\n",
    "    traci.gui.screenshot(traci.gui.DEFAULT_VIEW, file_path)\n",
    "\n",
    "def agent_predict(env, model, episodes, save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    rewards_per_episode = []  # List to store rewards for each episode\n",
    "    all_average_waiting_times = []  # List to store average waiting times for each episode\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        obs, info = env.reset()\n",
    "        step = 0\n",
    "        total_reward = 0  # Variable to store total reward for the episode\n",
    "        truncated = False\n",
    "        step_waiting_times = []  # List to store waiting times for this episode\n",
    "\n",
    "        while not truncated:\n",
    "            action, _states = model.predict(obs)\n",
    "            results = env.step(action)\n",
    "            if len(results) == 5:\n",
    "                obs, rewards, _, truncated, info = results\n",
    "                if truncated:\n",
    "                    print(f\"Truncated: {truncated}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Expected 5 values from env.step(), got {len(results)}\")\n",
    "            total_reward += rewards  # Accumulate rewards\n",
    "\n",
    "            # Collect waiting times at each step\n",
    "            total_waiting_time = 0\n",
    "            vehicle_count = 0\n",
    "            for veh_id in traci.vehicle.getIDList():\n",
    "                total_waiting_time += traci.vehicle.getWaitingTime(veh_id)\n",
    "                vehicle_count += 1\n",
    "\n",
    "            # Calculate the average waiting time for this step\n",
    "            if vehicle_count > 0:\n",
    "                average_waiting_time = total_waiting_time / vehicle_count\n",
    "            else:\n",
    "                average_waiting_time = 0\n",
    "\n",
    "            step_waiting_times.append(average_waiting_time)\n",
    "\n",
    "            # Capture and save the environment state every 10 steps\n",
    "            # if step % 10 == 0:\n",
    "            #     capture_screenshot(save_path, episode, step)\n",
    "            \n",
    "            step += 1\n",
    "\n",
    "        rewards_per_episode.append(total_reward)  # Append total reward for this episode\n",
    "        all_average_waiting_times.append(step_waiting_times)  # Append waiting times for this episode\n",
    "\n",
    "    return rewards_per_episode, all_average_waiting_times\n",
    "\n",
    "def plot_average_waiting_times(all_average_waiting_times, duration):\n",
    "    avg_waiting_times_per_step = [sum(times) / len(times) for times in zip(*all_average_waiting_times)]\n",
    "    overall_avg_waiting_time = sum(avg_waiting_times_per_step) / len(avg_waiting_times_per_step)\n",
    "    print(f\"Overall Average Waiting Time: {overall_avg_waiting_time:.2f} seconds\")\n",
    "    \n",
    "    plt.plot(avg_waiting_times_per_step, label='Average Waiting Time')\n",
    "    plt.axhline(y=overall_avg_waiting_time, color='r', linestyle='--', label='Average Waiting Time')\n",
    "\n",
    "    plt.title('Average Waiting Time per Simulation Step over Episodes')\n",
    "    plt.xlabel('Simulation Step')\n",
    "    plt.ylabel('Waiting Time (s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    save_figures('Outputs/single-intersection/graphs', 'agent_average_waiting_times')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_total_rewards(rewards_per_episode):\n",
    "    plt.plot(range(1, len(rewards_per_episode) + 1), rewards_per_episode)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Improvement in Total Reward over Episodes')\n",
    "    plt.grid(True)\n",
    "    save_figures('Outputs/single-intersection/graphs', 'agent_total_rewards')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Connecting to SUMO server...\")\n",
    "traci_connection_predict = traci.connect(port=65533)\n",
    "print(\"Connected to SUMO server\")\n",
    "\n",
    "# Parameters\n",
    "episodes = 10\n",
    "duration = 3600  # in seconds\n",
    "port = 65533\n",
    "save_path = 'Outputs/single-intersection/dqn_images'\n",
    "\n",
    "env_dqn_agent = initialize_sumo_environment(num_seconds, min_green, max_green, 'DQN_Agent_Prediction')\n",
    "loaded_model = DQN.load('savedAgent/single-intersection/dqnEpNum10_20240704_004515.zip')\n",
    "\n",
    "# Run the simulation over multiple episodes and collect average waiting times per step\n",
    "rewards_per_episode, all_average_waiting_times = agent_predict(env_dqn_agent, loaded_model, episodes, save_path)\n",
    "traci.close()\n",
    "# Plot the average waiting times per simulation step\n",
    "plot_average_waiting_times(all_average_waiting_times, duration)\n",
    "\n",
    "# Plot the total rewards per episode\n",
    "plot_total_rewards(rewards_per_episode)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b3c8c50cd03c5481",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a Video from the Captured Images"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c0e6619e85ecfe6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def create_video(output_path, title):\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(output_path)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(output_path, file_name)\n",
    "            images.append(imageio.imread(file_path))\n",
    "    video_path = f'{title}.mp4'\n",
    "    imageio.mimsave(video_path, images, fps=10)\n",
    "    return Video(video_path)\n",
    "\n",
    "\n",
    "create_video(\"outputs/single-intersection/dqn_images\", \"DQN Agent Solution\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9b5b15b904a04a36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualizing and Analyzing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ccd9c919dfb35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Waiting time per episode"
   ]
  },
  {
   "cell_type": "code",
   "id": "78861701e9e79222",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def plot_metrics(data, title, ax):\n",
    "    ax.plot(data['step'], data['system_mean_waiting_time'], label='System Mean Waiting Time')\n",
    "    ax.set_xlabel('Step Time')\n",
    "    ax.set_ylabel('System Mean Waiting Time')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "def visualize_results():\n",
    "    episodes = range(1, 40, 5)\n",
    "    fig, axs = plt.subplots(len(episodes)//2, 2, figsize=(15, 20))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, episode in enumerate(episodes):\n",
    "        file_path = f\"Outputs/single-intersection/DQN_Agent_Training/dqn_20240614_104927_conn17_ep{episode}.csv\"\n",
    "        title = f\"DQN Agent Solution - Episode {episode}\"\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            if 'step' not in data.columns or 'system_mean_waiting_time' not in data.columns:\n",
    "                raise KeyError(\"CSV file does not contain required columns: 'step' and 'system_mean_waiting_time'\")\n",
    "            \n",
    "            plot_metrics(data, title, axs[i])\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_results()\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d4232cc958ceb470",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Average Waiting Time in Naive Solution"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb934e3485fd4f98",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "def plot_waiting_time(xml_file_path):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    depart_times = []\n",
    "    waiting_times = []\n",
    "\n",
    "    for tripinfo in root.findall('tripinfo'):\n",
    "        depart_time = float(tripinfo.get('depart'))\n",
    "        waiting_time = float(tripinfo.get('waitingTime'))\n",
    "\n",
    "        depart_times.append(depart_time)\n",
    "        waiting_times.append(waiting_time)\n",
    "\n",
    "    average_waiting_time = sum(waiting_times) / len(waiting_times)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(depart_times, waiting_times, label='Waiting Time')\n",
    "    plt.axhline(y=average_waiting_time, color='r', linestyle='--', label='Average Waiting Time')\n",
    "    plt.xlabel('Departure Time')\n",
    "    plt.ylabel('Waiting Time')\n",
    "    plt.title('Waiting Time for Vehicles')\n",
    "    plt.legend()\n",
    "    save_figures('Outputs/single-intersection/graphs', 'naive_waiting_time')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Average Waiting Time: {average_waiting_time:.2f} seconds\")\n",
    "\n",
    "# Example usage\n",
    "xml_file_path = 'Outputs/fixed_time_policy/trip_info.xml'\n",
    "plot_waiting_time(xml_file_path)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b46a0799682f5613",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Calculate the Overall Average Waiting Time"
   ]
  },
  {
   "cell_type": "code",
   "id": "96b202e56f741ffc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def plot_average_waiting_time(file_path, episodes, title):\n",
    "    mean_average_waiting_time = 0\n",
    "    list_of_average = []\n",
    "\n",
    "    for episode in episodes:\n",
    "        episode_file_path = f'{file_path}_ep{episode}.csv'\n",
    "        data = pd.read_csv(episode_file_path)\n",
    "        average_waiting_time = data['system_mean_waiting_time'].mean()\n",
    "        mean_average_waiting_time += average_waiting_time\n",
    "        list_of_average.append(average_waiting_time)\n",
    "\n",
    "    overall_mean_average_waiting_time = mean_average_waiting_time / len(episodes)\n",
    "    print(f'The overall average waiting time is: {overall_mean_average_waiting_time}\\n')\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(episodes, list_of_average, marker='o', linestyle='-', color='r', label='Avg Waiting Time')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Waiting Time')\n",
    "    plt.title(f'Improvement in System Mean Waiting Time over Episodes - {title}')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.axhline(y=overall_mean_average_waiting_time, color='b', linestyle='--', label='Average Waiting Time')\n",
    "    save_figures('Outputs/single-intersection/graphs', f'{title}_average_waiting_time')\n",
    "    plt.show()\n",
    "\n",
    "agent_file_path = '/Users/md/Desktop/Traffic_Tune_Project/Outputs/Training/single_intersection/experiments/07.09-14:20:21_conn0'\n",
    "# agen_prediction_file_path = \"Outputs/single-intersection/DQN_Agent_Prediction/dqn_20240704_004515_conn11\"\n",
    "episods_learning_phase = range(1, 17) # Change the range as needed\n",
    "episods_prediction_phase = range(1, 10) # Change the range as needed\n",
    "\n",
    "plot_average_waiting_time(agent_file_path, episods_learning_phase, 'DQN Agent Learning')\n",
    "# plot_average_waiting_time(agen_prediction_file_path, episods_prediction_phase, 'DQN Agent Prediction')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cb9b4a870441c020",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
