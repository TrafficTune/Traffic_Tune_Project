{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a145c81c2dbf7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Traffic Tune - Optimizing Traffic Signals with Reinforcement Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the Traffic Tune POC notebook. Our project focused on optimizing traffic signal control using reinforcement learning. Traffic congestion is a major problem in urban areas, leading to increased travel times, fuel consumption, and pollution. Traditional traffic signal control systems often struggle to adapt to dynamic traffic conditions, resulting in suboptimal traffic flow.\n",
    "\n",
    "Traffic Tune is a recommendation system that leverages reinforcement learning to dynamically adjust traffic signals at intersections. By learning from traffic patterns in real-time, Traffic Tune aims to improve traffic flow, reduce congestion, and enhance overall transportation efficiency.\n",
    "\n",
    "In this POC, we will demonstrate how to train a reinforcement learning agent to optimize traffic signal control in a simulated environment. We will use the SUMO (Simulation of Urban MObility) traffic simulation tool and the Stable Baselines3 library to train a Deep Q-Network (DQN) agent to learn an optimal traffic signal control policy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476f7866dc519ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup and Installations"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:02:37.448591Z",
     "start_time": "2024-07-21T21:02:35.758572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import env_manager as env_manager\n",
    "import ppo_trainer as ppo_trainer"
   ],
   "id": "325ce834970de795",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:02:37.451301Z",
     "start_time": "2024-07-21T21:02:37.449481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_intersection_to_train = 4 # Choose which intersection you want to train\n",
    "\n",
    "experiment_type = \"SingleAgent\" # Choose the experiment_type: SingleAgent | MultiAgent"
   ],
   "id": "c1aea9551bb990a7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "env setup",
   "id": "9ca6bdb038bc5642"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:02:37.454933Z",
     "start_time": "2024-07-21T21:02:37.452048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "manager = env_manager.EnvManager(f\"{experiment_type}Environment\", \"env_config.json\", json_id=f\"intersection_{num_intersection_to_train}\")\n",
    "generator = manager.env_generator(f\"Nets/intersection_{num_intersection_to_train}/route_xml_path_intersection_{num_intersection_to_train}.txt\")\n",
    "rou , csv = next(generator)\n",
    "env_kwargs = manager.initialize_env(rou, csv)\n",
    "\n",
    "print(f\"\\nEnv creat for intersection_{num_intersection_to_train}\",\n",
    "      \"\\nNet path:\", manager.kwargs[\"net_file\"],\n",
    "      \"\\nRoute path:\", rou,\n",
    "      \"\\nCsv path:\", csv)"
   ],
   "id": "3dbaca67cce7f5c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Env creat for intersection_4 \n",
      "Net path: Nets/intersection_4/intersection_4.net.xml \n",
      "Route path: Nets/intersection_4/routes_4/intersection_4_random_easy_1.rou.xml \n",
      "Csv path: Outputs/Training/intersection_4/experiments/intersection_4_random_easy_1_07.22-00:02:37\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "agent setup",
   "id": "b64cd532db18accd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:02:39.481204Z",
     "start_time": "2024-07-21T21:02:37.456124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ppo_agent = ppo_trainer.PPOTrainer(\"ppo_config.json\", manager, experiment_type=experiment_type)\n",
    "ppo_agent.build_config()"
   ],
   "id": "8309087ffdba4187",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:02:39,024\tINFO worker.py:1771 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.rllib.algorithms.ppo.ppo.PPOConfig at 0x11118f760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "agent training",
   "id": "ffd34e669e6861c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = ppo_agent.train()",
   "id": "94b0bb667ed4bf91",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:02:39,581\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_cpus_per_worker` has been deprecated. Use `AlgorithmConfig.num_cpus_per_env_runner` instead. This will raise an error in the future!\n",
      "2024-07-22 00:02:39,581\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_gpus_per_worker` has been deprecated. Use `AlgorithmConfig.num_gpus_per_env_runner` instead. This will raise an error in the future!\n",
      "2024-07-22 00:02:39,581\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_learner_workers` has been deprecated. Use `AlgorithmConfig.num_learners` instead. This will raise an error in the future!\n",
      "2024-07-22 00:02:39,582\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_cpus_per_learner_worker` has been deprecated. Use `AlgorithmConfig.num_cpus_per_learner` instead. This will raise an error in the future!\n",
      "2024-07-22 00:02:39,582\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_gpus_per_learner_worker` has been deprecated. Use `AlgorithmConfig.num_gpus_per_learner` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-07-22 00:04:53</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:14.15        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.4/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_\n",
       "sample_reqs</th><th style=\"text-align: right;\">  num_remote_worker_re\n",
       "starts</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_PPO_9076e_00000</td><td>TERMINATED</td><td>127.0.0.1:33236</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.588</td><td style=\"text-align: right;\">4320</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:04:53,731\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_4/saved_agent/PPO_2024-07-22_00-02-39' in 0.0082s.\n",
      "2024-07-22 00:05:03,483\tINFO tune.py:1041 -- Total run time: 144.00 seconds (134.14 seconds for the tuning loop).\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T21:05:03.496765Z",
     "start_time": "2024-07-21T21:05:03.494202Z"
    }
   },
   "cell_type": "code",
   "source": "print(results.get_best_result())",
   "id": "30f290fd8430f049",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'evaluation': {'env_runners': {'episode_reward_max': -4.120000000000002, 'episode_reward_min': -4.120000000000002, 'episode_reward_mean': -4.120000000000002, 'episode_len_mean': 720.0, 'episode_media': {}, 'episodes_timesteps_total': 720, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-4.120000000000002], 'episode_lengths': [720]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.5980213402708496, 'mean_inference_ms': 0.3973026947456844, 'mean_action_processing_ms': 0.04702149549979571, 'mean_env_wait_ms': 13.809121538481767, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0021219253540039062, 'StateBufferConnector_ms': 0.0019311904907226562, 'ViewRequirementAgentConnector_ms': 0.043010711669921875}, 'num_episodes': 1, 'episode_return_max': -4.120000000000002, 'episode_return_min': -4.120000000000002, 'episode_return_mean': -4.120000000000002, 'episodes_this_iter': 1}, 'num_agent_steps_sampled_this_iter': 720, 'num_env_steps_sampled_this_iter': 720, 'timesteps_this_iter': 720, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 1, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 1.1816144807772202, 'cur_kl_coeff': 0.006249999999999999, 'cur_lr': 2.0000000000000005e-05, 'total_loss': 0.23928273679180578, 'policy_loss': -0.002789226800880649, 'vf_loss': 1.3946815154769203, 'vf_explained_var': 0.01778641884977167, 'kl': 0.0004080633845541793, 'entropy': 1.0660096547820352, 'entropy_coeff': 0.09999999999999998}, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 64.0, 'num_grad_updates_lifetime': 605.5, 'diff_num_grad_updates_vs_sampler_policy': 54.5}}, 'num_env_steps_sampled': 4320, 'num_env_steps_trained': 4320, 'num_agent_steps_sampled': 4320, 'num_agent_steps_trained': 4320, 'num_env_steps_sampled_for_evaluation_this_iter': 720}, 'env_runners': {'episode_reward_max': -0.99, 'episode_reward_min': -8.12, 'episode_reward_mean': -4.1866666666666665, 'episode_len_mean': 720.0, 'episode_media': {}, 'episodes_timesteps_total': 4320, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-5.47, -0.99, -7.15, -1.9, -8.12, -1.4900000000000007], 'episode_lengths': [720, 720, 720, 720, 720, 720]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.6199229491596798, 'mean_inference_ms': 0.44658224953009734, 'mean_action_processing_ms': 0.05359888180829811, 'mean_env_wait_ms': 15.935844970491852, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.003918011983235677, 'StateBufferConnector_ms': 0.0022570292154947915, 'ViewRequirementAgentConnector_ms': 0.06111065546671549}, 'num_episodes': 1, 'episode_return_max': -0.99, 'episode_return_min': -8.12, 'episode_return_mean': -4.1866666666666665, 'episodes_this_iter': 1}, 'num_healthy_workers': 1, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4320, 'num_agent_steps_trained': 4320, 'num_env_steps_sampled': 4320, 'num_env_steps_trained': 4320, 'num_env_steps_sampled_this_iter': 720, 'num_env_steps_trained_this_iter': 720, 'num_env_steps_sampled_throughput_per_sec': 61.19500583398414, 'num_env_steps_trained_throughput_per_sec': 61.19500583398414, 'num_env_steps_sampled_lifetime': 4320, 'num_agent_steps_sampled_lifetime': 4320, 'num_steps_trained_this_iter': 720, 'agent_timesteps_total': 4320, 'timers': {'training_iteration_time_ms': 12856.602, 'restore_workers_time_ms': 0.014, 'training_step_time_ms': 12856.567, 'sample_time_ms': 12647.21, 'restore_eval_workers_time_ms': 0.008, 'evaluation_iteration_time_ms': 20929.185, 'evaluation_iteration_throughput': 34.402, 'load_time_ms': 0.282, 'load_throughput': 2556347.81, 'learn_time_ms': 207.227, 'learn_throughput': 3474.449, 'synch_weights_time_ms': 1.653}, 'counters': {'num_env_steps_sampled': 4320, 'num_env_steps_trained': 4320, 'num_agent_steps_sampled': 4320, 'num_agent_steps_trained': 4320, 'num_env_steps_sampled_for_evaluation_this_iter': 720}, 'perf': {'cpu_util_percent': 31.20344827586207, 'ram_util_percent': 71.2}},\n",
      "  path='/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_4/saved_agent/PPO_2024-07-22_00-02-39/PPO_PPO_9076e_00000_0_2024-07-22_00-02-39',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_4/saved_agent/PPO_2024-07-22_00-02-39/PPO_PPO_9076e_00000_0_2024-07-22_00-02-39/checkpoint_000005)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "agent prediction",
   "id": "51f4ac4280880d68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ppo_agent.evaluate(results=results, kwargs=env_kwargs)",
   "id": "c49972e77b501485",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best = results.get_best_result(\"env_runners/episode_reward_max\", \"max\")\n",
    "print(best)"
   ],
   "id": "106ea8376d47f062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rou , csv = next(generator)\n",
    "print(rou)\n",
    "print(csv)\n",
    "env_kwargs = manager.initialize_env(rou, csv)\n",
    "print(env_kwargs)"
   ],
   "id": "3268ffa1ca0a9774",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppo_agent.config = best.config\n",
    "ppo_agent.build_config(env_kwargs)"
   ],
   "id": "4c7c2003ddb31e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_2 = ppo_agent.train()",
   "id": "588eabfc632d79d7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
