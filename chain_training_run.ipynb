{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a145c81c2dbf7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Traffic Tune - Optimizing Traffic Signals with Reinforcement Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the Traffic Tune POC notebook. Our project focused on optimizing traffic signal control using reinforcement learning. Traffic congestion is a major problem in urban areas, leading to increased travel times, fuel consumption, and pollution. Traditional traffic signal control systems often struggle to adapt to dynamic traffic conditions, resulting in suboptimal traffic flow.\n",
    "\n",
    "Traffic Tune is a recommendation system that leverages reinforcement learning to dynamically adjust traffic signals at intersections. By learning from traffic patterns in real-time, Traffic Tune aims to improve traffic flow, reduce congestion, and enhance overall transportation efficiency.\n",
    "\n",
    "In this POC, we will demonstrate how to train a reinforcement learning agent to optimize traffic signal control in a simulated environment. We will use the SUMO (Simulation of Urban MObility) traffic simulation tool and the Stable Baselines3 library to train a Deep Q-Network (DQN) agent to learn an optimal traffic signal control policy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476f7866dc519ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup and Installations"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T10:48:15.329541Z",
     "start_time": "2024-07-25T10:48:13.562947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import env_manager as env_manager\n",
    "import algo_trainer as algo_trainer\n",
    "from typing import SupportsIndex"
   ],
   "id": "325ce834970de795",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T10:48:15.334157Z",
     "start_time": "2024-07-25T10:48:15.330599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chain_training(manager: env_manager, generator: env_manager.EnvManager.env_generator, algo_agent, running_result: list):\n",
    "    if len(running_result) != 0: \n",
    "        # take the best config from the previous training \n",
    "        best = running_result[-1].get_best_result(\"env_runners/episode_reward_max\", \"max\")\n",
    "        \n",
    "        # Initialize the environment manager with new route file\n",
    "        rou, csv = next(generator)\n",
    "        manager.initialize_env(rou, csv)\n",
    "        \n",
    "        # continue the training with the best config\n",
    "        algo_agent.config = best.config\n",
    "        algo_agent.build_config()\n",
    "    \n",
    "    result = algo_agent.train()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def training(num_intersection: int, experiment_type: str, algo_config: str, env_config: str, num_training: SupportsIndex):\n",
    "    running_result = []\n",
    "    sumo_type = \"SingleAgent\"\n",
    "    algo_type = experiment_type.split(\"_\")\n",
    "     \n",
    "    if experiment_type.__contains__(\"Multi\"):\n",
    "        sumo_type = \"MultiAgent\"\n",
    "    \n",
    "    # Initialize the environment manager\n",
    "    manager = env_manager.EnvManager(f\"{sumo_type}Environment\", env_config, json_id=f\"intersection_{num_intersection}\")\n",
    "    generator = manager.env_generator(f\"Nets/intersection_{num_intersection}/route_xml_path_intersection_{num_intersection}.txt\", algo_name=algo_type[0])\n",
    "    \n",
    "    # Initialize the environment manager with new route file\n",
    "    rou, csv = next(generator)\n",
    "    manager.initialize_env(rou, csv)\n",
    "    \n",
    "    algo_agent = algo_trainer.ALGOTrainer(config_path=algo_config, env_manager=manager, experiment_type=experiment_type)\n",
    "    algo_agent.build_config()\n",
    "\n",
    "    for i in range(num_training):\n",
    "        chain_result = chain_training(manager=manager, generator=generator, algo_agent=algo_agent, running_result=running_result)\n",
    "        if chain_result is not None:\n",
    "            running_result.append(chain_result)\n",
    "    \n",
    "    return running_result"
   ],
   "id": "57e8fffd58eb2107",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T10:48:15.336609Z",
     "start_time": "2024-07-25T10:48:15.334933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_intersection_to_train = 2  # Choose which intersection you want to train\n",
    "\n",
    "# Choose the experiment_type:\n",
    "# PPO_SingleAgent | PPO_MultiAgent | DQN_SingleAgent | DDQN_SingleAgent | DQN_MultiAgent | DDQN_MultiAgent\n",
    "experiment_type = \"DQN_SingleAgent\"  \n",
    "\n",
    "num_training_cycles = 1\n",
    "\n",
    "env_config_file_path = \"env_config.json\"\n",
    "\n",
    "ppo_config_file_path = \"ppo_config.json\"\n",
    "\n",
    "dqn_config_file_path = \"dqn_config.json\""
   ],
   "id": "c1aea9551bb990a7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = training(num_intersection=num_intersection_to_train, experiment_type=experiment_type, algo_config=dqn_config_file_path, env_config=env_config_file_path, num_training=num_training_cycles)\n",
    "experiment_type = \"DDQN_SingleAgent\"\n",
    "results_1 = training(num_intersection=num_intersection_to_train, experiment_type=experiment_type, algo_config=dqn_config_file_path, env_config=env_config_file_path, num_training=num_training_cycles)\n",
    "experiment_type = \"PPO_SingleAgent\"\n",
    "results_2 = training(num_intersection=num_intersection_to_train, experiment_type=experiment_type, algo_config=ppo_config_file_path, env_config=env_config_file_path, num_training=num_training_cycles)"
   ],
   "id": "63800ac021cb3fc2",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 13:56:58,527\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_cpus_per_worker` has been deprecated. Use `AlgorithmConfig.num_cpus_per_env_runner` instead. This will raise an error in the future!\n",
      "2024-07-25 13:56:58,528\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_gpus_per_worker` has been deprecated. Use `AlgorithmConfig.num_gpus_per_env_runner` instead. This will raise an error in the future!\n",
      "2024-07-25 13:56:58,528\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_learner_workers` has been deprecated. Use `AlgorithmConfig.num_learners` instead. This will raise an error in the future!\n",
      "2024-07-25 13:56:58,528\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_cpus_per_learner_worker` has been deprecated. Use `AlgorithmConfig.num_cpus_per_learner` instead. This will raise an error in the future!\n",
      "2024-07-25 13:56:58,528\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_gpus_per_learner_worker` has been deprecated. Use `AlgorithmConfig.num_gpus_per_learner` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-07-25 13:58:45</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:47.35        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.7/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_\n",
       "sample_reqs</th><th style=\"text-align: right;\">  num_remote_worker_re\n",
       "starts</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_PPO_9d2a3_00000</td><td>TERMINATED</td><td>127.0.0.1:7621</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         98.5591</td><td style=\"text-align: right;\">3600</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m 2024-07-25 13:57:00,532\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_cpus_per_worker` has been deprecated. Use `AlgorithmConfig.num_cpus_per_env_runner` instead. This will raise an error in the future!\n",
      "\u001B[36m(PPO pid=7621)\u001B[0m 2024-07-25 13:57:00,532\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_gpus_per_worker` has been deprecated. Use `AlgorithmConfig.num_gpus_per_env_runner` instead. This will raise an error in the future!\n",
      "\u001B[36m(PPO pid=7621)\u001B[0m 2024-07-25 13:57:00,532\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_learner_workers` has been deprecated. Use `AlgorithmConfig.num_learners` instead. This will raise an error in the future!\n",
      "\u001B[36m(PPO pid=7621)\u001B[0m 2024-07-25 13:57:00,532\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_cpus_per_learner_worker` has been deprecated. Use `AlgorithmConfig.num_cpus_per_learner` instead. This will raise an error in the future!\n",
      "\u001B[36m(PPO pid=7621)\u001B[0m 2024-07-25 13:57:00,532\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.num_gpus_per_learner_worker` has been deprecated. Use `AlgorithmConfig.num_gpus_per_learner` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m  Retrying in 1 seconds\n",
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 6ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 30ms, vehicles TOT 3632 ACT 48 BUF 1)               ACT 0 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 4ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m  Retrying in 1 seconds\u001B[32m [repeated 2x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_2/saved_agent/PPO_2024-07-25_13-56-58/PPO_PPO_9d2a3_00000_0_2024-07-25_13-56-58/checkpoint_000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 36ms, vehicles TOT 3590 ACT 44 BUF 0)               ACT 0 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m  Retrying in 1 seconds\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 23ms, vehicles TOT 3513 ACT 30 BUF 2)               CT 0 BUF 0)                       \n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 26ms, vehicles TOT 3547 ACT 51 BUF 2)               ACT 1 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 23ms, vehicles TOT 3680 ACT 31 BUF 0)               ACT 1 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 27ms, vehicles TOT 3649 ACT 47 BUF 0)               ACT 0 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 25ms, vehicles TOT 3529 ACT 36 BUF 0)               ACT 2 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_2/saved_agent/PPO_2024-07-25_13-56-58/PPO_PPO_9d2a3_00000_0_2024-07-25_13-56-58/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 32ms, vehicles TOT 3540 ACT 46 BUF 9)               ACT 1 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m  Retrying in 1 seconds\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 25ms, vehicles TOT 3659 ACT 50 BUF 3)               ACT 2 BUF 0)                      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_2/saved_agent/PPO_2024-07-25_13-56-58/PPO_PPO_9d2a3_00000_0_2024-07-25_13-56-58/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3600.00 (1ms ~= 1000.00*RT, ~44000.00UPS, TraCI: 31ms, vehicles TOT 3524 ACT 44 BUF ACT 2 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m  Retrying in 1 seconds\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Step #3600.00 (1ms ~= 1000.00*RT, ~31000.00UPS, TraCI: 24ms, vehicles TOT 3525 ACT 31 BUF ACT 2 BUF 0)                      \n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 24ms, vehicles TOT 3677 ACT 46 BUF 19)              ACT 1 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 23ms, vehicles TOT 3533 ACT 36 BUF 0)               ACT 0 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 25ms, vehicles TOT 3703 ACT 37 BUF 8)               CT 0 BUF 0)                       \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_2/saved_agent/PPO_2024-07-25_13-56-58/PPO_PPO_9d2a3_00000_0_2024-07-25_13-56-58/checkpoint_000003)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 29ms, vehicles TOT 3582 ACT 40 BUF 0)               ACT 1 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7630)\u001B[0m  Retrying in 1 seconds\n",
      "Step #3600.00 (0ms ?*RT. ?UPS, TraCI: 29ms, vehicles TOT 3696 ACT 44 BUF 0)               ACT 1 BUF 0)                      \n",
      "\u001B[36m(RolloutWorker pid=7622)\u001B[0m  Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(PPO pid=7621)\u001B[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_2/saved_agent/PPO_2024-07-25_13-56-58/PPO_PPO_9d2a3_00000_0_2024-07-25_13-56-58/checkpoint_000004)\n",
      "2024-07-25 13:58:45,879\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/eviat/Desktop/Final_Project/Traffic_Tune_Project/Outputs/Training/intersection_2/saved_agent/PPO_2024-07-25_13-56-58' in 0.0082s.\n",
      "2024-07-25 13:58:46,457\tINFO tune.py:1041 -- Total run time: 107.94 seconds (107.34 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5.00 (0ms ?*RT. ?UPS, TraCI: 782ms, vehicles TOT 10 ACT 10 BUF 0)                   ACT 1 BUF 0)                      \n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T11:03:54.536050Z",
     "start_time": "2024-07-25T11:03:54.531591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming the result is stored in a variable named `result_grid`\n",
    "result = results[0]\n",
    "result = result[0]\n",
    "print(\"DQN\\n\",result.metrics.get(\"evaluation\", {}),\"\\n\\n\")\n",
    "\n",
    "result1 = results_1[0]\n",
    "result1 = result1[0]\n",
    "print(\"DDQN\\n\",result1.metrics.get(\"evaluation\", {}),\"\\n\\n\")\n",
    "\n",
    "result2 = results_2[0]\n",
    "result2 = result2[0]\n",
    "print(\"PPO\\n\",result2.metrics.get(\"evaluation\", {}),\"\\n\\n\")\n",
    "\n"
   ],
   "id": "4941fe2a1ffc0e09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN\n",
      " {'env_runners': {'episode_reward_max': -0.17000000000000018, 'episode_reward_min': -1.8899999999999997, 'episode_reward_mean': -0.8925000000000006, 'episode_len_mean': 720.0, 'episode_media': {}, 'episodes_timesteps_total': 2880, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-0.17000000000000018, -1.8899999999999997, -1.050000000000001, -0.46000000000000113], 'episode_lengths': [720, 720, 720, 720]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.6125261472809571, 'mean_inference_ms': 0.431369241189615, 'mean_action_processing_ms': 0.04417968598327324, 'mean_env_wait_ms': 41.01937919259143, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0025212764739990234, 'StateBufferConnector_ms': 0.0018894672393798828, 'ViewRequirementAgentConnector_ms': 0.03832578659057617}, 'num_episodes': 4, 'episode_return_max': -0.17000000000000018, 'episode_return_min': -1.8899999999999997, 'episode_return_mean': -0.8925000000000006, 'episodes_this_iter': 4}, 'num_agent_steps_sampled_this_iter': 2880, 'num_env_steps_sampled_this_iter': 2880, 'timesteps_this_iter': 2880, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 1, 'num_remote_worker_restarts': 0} \n",
      "\n",
      "\n",
      "DDQN\n",
      " {'env_runners': {'episode_reward_max': -40.13, 'episode_reward_min': -40.72, 'episode_reward_mean': -40.435, 'episode_len_mean': 720.0, 'episode_media': {}, 'episodes_timesteps_total': 2880, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-40.58, -40.72, -40.13, -40.31], 'episode_lengths': [720, 720, 720, 720]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.6040913261067113, 'mean_inference_ms': 0.40361735687811606, 'mean_action_processing_ms': 0.043329741151180184, 'mean_env_wait_ms': 27.102494264629975, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0025451183319091797, 'StateBufferConnector_ms': 0.0016868114471435547, 'ViewRequirementAgentConnector_ms': 0.03902912139892578}, 'num_episodes': 4, 'episode_return_max': -40.13, 'episode_return_min': -40.72, 'episode_return_mean': -40.435, 'episodes_this_iter': 4}, 'num_agent_steps_sampled_this_iter': 2880, 'num_env_steps_sampled_this_iter': 2880, 'timesteps_this_iter': 2880, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 1, 'num_remote_worker_restarts': 0} \n",
      "\n",
      "\n",
      "PPO\n",
      " {'env_runners': {'episode_reward_max': -0.19999999999999998, 'episode_reward_min': -1.2399999999999987, 'episode_reward_mean': -0.8499999999999999, 'episode_len_mean': 720.0, 'episode_media': {}, 'episodes_timesteps_total': 2880, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-0.19999999999999998, -1.120000000000001, -1.2399999999999987, -0.8399999999999997], 'episode_lengths': [720, 720, 720, 720]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.573570978412211, 'mean_inference_ms': 0.3593492827108019, 'mean_action_processing_ms': 0.044697848120479, 'mean_env_wait_ms': 9.236449050808556, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.002849102020263672, 'StateBufferConnector_ms': 0.00209808349609375, 'ViewRequirementAgentConnector_ms': 0.04303455352783203}, 'num_episodes': 4, 'episode_return_max': -0.19999999999999998, 'episode_return_min': -1.2399999999999987, 'episode_return_mean': -0.8499999999999999, 'episodes_this_iter': 4}, 'num_agent_steps_sampled_this_iter': 2880, 'num_env_steps_sampled_this_iter': 2880, 'timesteps_this_iter': 2880, 'num_healthy_workers': 1, 'num_in_flight_async_reqs': 1, 'num_remote_worker_restarts': 0} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6075a141ae8027df",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
